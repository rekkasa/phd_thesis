# Estimating individualized treatment effects from clinical trial data {#sec-simulation-appendix}
\chaptermark{Individualized treatment effects}
\vspace*{\fill}\par
\pagebreak

```{r, echo=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(knitr)
library(here)
library(rms)
library(kableExtra)

d <- function(x, decimals = 2) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}
knit_hooks$set(
  inline = function(x) {
    prettyNum(
      x,
      format = "f",
      big.mark = ",",
      decimal.mark = ".",
      preserve.width = "individual"
    )
  }
)
```

## Notation {.unnumbered}
We observe RCT data $(Z, X, Y)$, where for each patient $Z_i= 0, 1$ is the
treatment status, $Y_i = 0, 1$ is the observed outcome and $X_i$ is a set of
covariates measured. Let $\{Y_i(z), z=0, 1\}$ denote the unobservable potential
outcomes. We observe $Y_i = Z_iY_i(1) + (1 - Z_i)Y_i(0)$. We are interested in
predicting the conditional average treatment effect (CATE), 
$$\tau(x) = E\{Y(0) - Y(1)|X=x\}$$ 
Assuming that $(Z, X, Y)$ is a random sample from the target population and that
$\big(Y(0), Y(1)\big)\indep Z|X$, as we are in the RCT setting, we can predict
CATE from
\begin{align*}
\tau(x) &= E\{Y(0)\given X=x\}-E\{Y(1)\given X=x\}\\
&=E\{Y\given X=x, Z=0\}-E\{Y\given X=x, Z=1\}
\end{align*}

Based on an estimate of baseline risk
$$
E\{Y\given X=x, Z=0\}=g\big(\hat{lp}(x)\big)
$$
with $\hat{u}=\hat{lp}(x)=x^t\hat{\beta}$ the linear predictor and $g$ the link function,
we predict CATE from
$$
\hat{\tau}(x) = g\big(f(\hat{u}, 0)\big) - g\big(f(\hat{u}, 1)\big)
$$
where $f(u,z)$ describes interactions of the baseline risk linear predictor with
treatment.

## Simulation settings {.unnumbered}
For all patients we observe covariates $X_1,\dots,X_8$, of which $4$ are
continuous and $4$ are binary. More specifically,

\begin{equation*}
X_1,\dots,X_4 \sim N(0, 1)
\end{equation*}
\begin{equation*}
X_5,\dots,X_8 \sim B(1, 0.2)
\end{equation*}

We first, generate the binary outcomes $Y$ for the untreated patients ($Z=0$),
based on

\begin{equation} 
P(Y(0)=1\given X=x) = g(\beta_0 + \beta_1x_1+\dots+\beta_8x_8) = g(lp_0),
(\#eq:p0)
\end{equation}

where $$g(x) = \frac{e^x}{1+e^x}$$

For treated patients, outcomes are generated from:

\begin{equation}
P(Y = 1\given X=x, Z=1) = g(lp_1)
(\#eq:p1)
\end{equation}


where $$lp_1 = \gamma_2(lp_0-c)^2+\gamma_1(lp_0-c)+\gamma_0$$

### Base-case scenario {.unnumbered}
The base-case scenario assumes a constant odds ratio of $0.8$ in favor of
treatment. The simulated datasets are of size $n=4250$, where treatment is
allocated at random using a 50/50 split (80% power for the detection of an
unadjusted OR of 0.8, assuming an event rate of 20% in the untreated
arm). Outcome incidence in the untreated population is set at $20\%$. For the
development of the prediction model we use the model defined in \@ref(eq:p0)
including a constant treatment effect. When doing predictions, $Z$ is set to
$0$. The value of the true $\beta$ is such that the above prediction model
has an AUC of $0.75$.


The previously defined targets are achieved when $\beta=(-2.08,
0.49,\dots,0.49)^t$. For the derivations in the treatment arm we use
$\gamma=(\log(0.8), 1, 0)^t$.

### Deviations from base-case {.unnumbered}
We deviate from the base-case scenario in two ways. First, we alter the overall
target settings of sample size, overall treatment effect and prediction model
AUC. In a second stage, we consider settings that violate the assumption of a
constant relative treatment effect, using a model-based approach.

For the first part, we consider:

* Sample size:
  + $n=1064$
  + $n=17000$
* Overall treatment effect:
  + $OR=0.5$
  + $OR=1$
* Prediction performance:
  + $AUC=0.65$
  + $AUC=0.85$
  
We set the true risk model coefficients to be
$\beta = \big(-1.63,0.26,\dots,0.26\big)^t$ for $AUC=0.65$ and $\beta = \big(-2.7,0.82,\dots,0.82\big)^t$ 
for $AUC=0.85$. In both cases, $\beta_0$ is selected so that an event rate of
$20\%$ is maintained in the control arm.

For the second part linear, quadratic and non-monotonic deviations from the
assumption of constant relative effect are considered. We also consider
different intensity levels of these deviations. Finally, constant absolute
treatment-related harms are introduced, i.e. positive 
($0.25\times\text{true average benefit}$),
strong positive ($0.50\times\text{true average benefit}$) and negative
($-0.25\times\text{true average benefit}$; i.e. constant absolute
treatment-related benefit). In case of true absent treatment effects,
treatment-related harms are set to $1\%, 2\%$ and $-1\%$ for positive, strong
positive and negative setting, respectively. The settings for these deviations
are defined in Table ***ONLINE TABLE***.

## Approaches to individualize benefit predictions {.unnumbered}

### Risk modeling {.unnumbered}
Merging treatment arms, we develop prediction models including a constant relative treatment effect:

$$
P(Y=1\given X=x,Z=z) = g(x^t\beta + \delta_0 z)
$$ {#eq-risk}

We derive baseline risk predictions for patients by setting $Z=0$ in
\@ref(eq:risk). All methods for individualizing benefit predictions are 2-stage
methods, that start by fitting a model for predicting baseline risk. The
estimated linear predictor of this model is

\begin{equation*}
\hat{lp} = lp(x;\hat{\beta}) = x^t\hat{\beta}
\end{equation*}

### Risk stratification {.unnumbered}
Derive a prediction model using the same approach as above and divide the
population in equally sized risk-based subgroups. Estimate subgroup-specific
absolute benefit from the observed absolute differences. Subject-specific
benefit predictions are made by attributing to individuals their corresponding
subgroup-specific estimate.

### Constant treatment effect {.unnumbered}
Assuming a constant relative treatment effect, fit the adjusted model in
@eq-risk. Then, predict absolute benefit using 

$$
\hat{\tau}(x;\hat{\beta},\hat{\gamma})=g(f(\hat{lp}, 0)) - g(f(\hat{lp},1)), 
$$ {#eq-main}

where $f(\hat{lp}, z) = \hat{lp}+\hat{\delta}_0z$, with $\hat{\delta}_0$ the
estimated relative treatment effect (log odds ratio).

### Linear interaction {.unnumbered}
We relax the assumption of a constant relative treatment effect in
@eq-main by setting

$$ f(\hat{lp}, z) = \delta_0+\delta_1z+\delta_2\hat{lp}+\delta_3z\hat{lp} $$

### Restricted cubic splines {.unnumbered}
Finally, we drop the linearity assumption and predict absolute benefit using
smoothing with restricted cubic splines with $k=3, 4$ and $5$ knots. More
specifically, we set:

$$ f(\hat{lp}, z) = \delta_0 + \delta_1z+zs(\hat{lp}) $$
where
$$s(x)=\alpha_0+\alpha_1h_1(x)+\alpha_2h_2(x)+\dots+\alpha_{k-1}h_{k-1}(x)$$
with $h_1(x)=x$ and for $j=2,\dots,k-2$
$$h_{j+1}(x)= (x-t_j)^3-(x-t_{k-1})_+^3 \frac{t_k-t_j}{t_k-t_{k-1}}+(x-t_k)^3_+\frac{t_{k-1}-t_j}{t_k-t_{k-1}}$$
where 
$t_1,\dots,t_k$ are the selected knots [@harrell2017regression]. 


## Adaptive model selection frequencies {.unnumbered}
```{r fig-ch4-supp1, cache=TRUE, echo=FALSE, fig.pos="H", fig.cap="Model selection frequencies of the adaptive approach based on Akaike’s Information Criterion across 500 replications. The scenario with the true constant relative treatment effect (first panel) had a true prediction AUC of 0.75 and sample size of 4,250.",fig.align='center'}
grid::grid.raster(tiff::readTIFF(here::here("figures/ch4-Selected_model_adaptive_base.tiff")))
```


```{r fig-ch4-supp2, cache=TRUE, echo=FALSE, fig.pos="H", fig.cap=" Model selection frequencies of the adaptive approach based on Akaike’s Information Criterion across 500 replications. Sample size is 17,000.",fig.align='center'}
grid::grid.raster(tiff::readTIFF(here::here("figures/ch4-Selected_model_adaptive_sample_size.tiff")))
```

```{r fig-ch4-supp3, cache=TRUE, echo=FALSE, fig.pos="H", fig.cap="Model selection frequencies of the adaptive approach based on Akaike’s Information Criterion across 500 replications. AUC is 0.85.",fig.align='center'}
grid::grid.raster(tiff::readTIFF(here::here("figures/ch4-Selected_model_adaptive_auc.tiff")))
```


## Discrimination and calibration for benefit {.unnumbered}

The c-for-benefit represents the probability that from two randomly chosen
matched patient pairs with unequal observed benefit, the pair with greater
observed benefit also has a higher predicted benefit. To be able to calculate
observed benefit, patients in each treatment arm are ranked based on their
predicted benefit and then matched 1:1 across treatment arms. Observed treatment
benefit is defined as the difference of observed outcomes between the untreated
and the treated patient of each matched patient pair. Predicted benefit is
defined as the average of predicted benefit within each matched patient pair.

We evaluated calibration in a similar manner, using the integrated calibration
index (ICI) for benefit [@austin2019integrated]. The observed benefits are
regressed on the predicted benefits using a locally weighted scatterplot
smoother (loess). The ICI-for-benefit is the average absolute difference between
predicted and smooth observed benefit. Values closer to represent better
calibration.

```{r fig-ch4-supp4, cache=TRUE, echo=FALSE, fig.cap=" Discrimination for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.75 and sample size of 17,000.",fig.align='center'}
knitr::include_graphics("figures/ch4-discrimination_moderate_sample_size.pdf")
```

```{r fig-ch4-supp5, cache=TRUE, echo=FALSE, fig.cap=" Discrimination for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.85 and sample size of 4,250.",fig.align='center'}
knitr::include_graphics("figures/ch4-discrimination_moderate_auc.pdf")
```

```{r fig-ch4-supp6, cache=TRUE, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.75 and sample size of 17,000.",fig.align='center'}
knitr::include_graphics("figures/ch4-calibration_moderate_sample_size.pdf")
```

```{r fig-ch4-supp7, cache=TRUE, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.85 and sample size of 4,250.",fig.align='center'}
knitr::include_graphics("figures/ch4-calibration_moderate_auc.pdf")
```

## Strong relative treatment effect {.unnumbered}

Here we present the root mean squared error of the considered methods using
strong constant relative treatment effect ($\text{OR}=0.5$) as the
reference. Again, the same sample size and prediction performance settings were
considered along with the same settings for linear, quadratic and non-monotonic
deviations from the base case scenario of constant relative treatment effects
are considered. All results can be found at
[https://arekkas.shinyapps.io/simulation_viewer/](https://arekkas.shinyapps.io/simulation_viewer/).

## Treatment interactions {.unnumbered}

We carried out a smaller set of simulations, in which we assumed true
treatment-covariate interactions. Sample size was set to 4,250 and the AUC of
the true prediction model was set to 0.75. The following scenarios were
considered: 1) 4 true weak positive interactions
($\text{OR}_{Z=1} / \text{OR}_{Z=0}=0.83$); 2) 4 strong positive
interactions ($\text{OR}_{Z=1} / \text{OR}_{Z=0}=0.61$); 3) 2 weak and 2
strong positive interactions; 4) 4 weak negative interactions 
($\text{OR}_{Z=1} / \text{OR}_{Z=0}=1.17$); 5) 4 strong negative interactions 
($\text{OR}_{Z=1} / \text{OR}_{Z=0}=1.39$); 6) 2 weak and 2 strong negative
interactions; 7) combined positive and negative strong interactions. We also
considered constant treatment-related harms applied on the absolute scale to all
treated patients. The exact settings were: 1) absent treatment-related harms; 2)
moderate treatment-related harms, defined as 25\% of the average true benefit of the
scenario without treatment-related harms; 3) strong treatment-related harms
defined as 50\% of the true average benefit of the scenario without
treatment-related harms; 4) negative treatment-related harms (benefit), defined
as an absolute risk reduction for treated patients of 50\% of the true average
benefit of the scenario without treatment-related harms. The exact settings can
be found in Table ***ONLINE TABLE***.

```{r fig-ch4-supp8, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000 where treatment-covariate interactions all favoring treatment were considered.",fig.align='center'}
knitr::include_graphics("figures/ch4-rmse_interaction_positive.pdf")
```

```{r fig-ch4-supp9, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000 where treatment-covariate interactions all favoring the control were considered.",fig.align='center'}
knitr::include_graphics("figures/ch4-rmse_interaction_negative.pdf")
```

```{r fig-ch4-supp10, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000 where treatment-covariate interactions 2 favoring treatment and 2 favoring the control were considered.",fig.align='center'}
knitr::include_graphics("figures/ch4-rmse_interaction_combined.pdf")
```

## Correlated covariates {.unnumbered}

We analyzed the sensitivity of our results to correlation between baseline
characteristics by incuding additional simulation scenarios. We sampled
covariates $W_1,\dots,W_8\sim N(0, \Sigma)$. We generated four continuous
baseline covariates $X_1=W_1,\dots,X_4=W_4$ and four binary covariates with 20\%
prevalence $X_5=I(W_5>z_{0.8}), X_8=I(W_8>z_{0.8})$, where $I$ is the indicator
function. We selected the covariance matrix $\Sigma$ such that
$\text{cor}(X_i,X_j)=0.5$, for any $i\neq j$. More precisely, we set $\Sigma$ as
can be seen below:

\begin{equation*}
\Sigma = 
\begin{pmatrix}
1       & 0.5   & 0.5   & 0.5   & 0.708 & 0.708 & 0.708 & 0.708 \\
0.5     & 1     & 0.5   & 0.5   & 0.708 & 0.708 & 0.708 & 0.708 \\
0.5     & 0.5   & 1     & 0.5   & 0.708 & 0.708 & 0.708 & 0.708 \\
0.5     & 0.5   & 0.5   & 1     & 0.708 & 0.708 & 0.708 & 0.708 \\
0.708   & 0.708 & 0.708 & 0.708 & 1     & 0.745 & 0.745 & 0.745 \\
0.708   & 0.708 & 0.708 & 0.708 & 0.745 & 1     & 0.745 & 0.745 \\
0.708   & 0.708 & 0.708 & 0.708 & 0.745 & 0.745 & 1     & 0.745 \\
0.708   & 0.708 & 0.708 & 0.708 & 0.745 & 0.745 & 0.745 & 1
\end{pmatrix}
\end{equation*}

In order to ensure that the simulated datasets were comparable to the original
main simulation scenarios, i.e. control arm event rate of 20\% and true risk
model c-statistic (AUC) equal to the target, we needed to adjust the
coefficients of the true risk model. The exact settings of the simlation
scenarios for the sensitivity analyses can be found in Table ***ONLINE TABLE***.

We found no noticeable differences between methods for individualizing treatment
benefit predictions compared to the results of the simulation scenarios where
baseline covariates were assumed to be statistically independent (Figures
[-@fig-ch4-supp11] to [-@fig-ch4-supp13]).

```{r fig-ch4-supp11, cache=FALSE, echo=FALSE, fig.cap="RMSE of the sensitivity analyses assuming correlated baseline covariates. All considered methods were derived using simulated samples of size 4,250 and true prediction c-statistic of 0.75.",fig.align='center'}
knitr::include_graphics(here::here("figures/ch4-rmse_moderate_base_sensitivity.pdf"))
```

```{r fig-ch4-supp12, cache=FALSE, echo=FALSE, fig.cap="RMSE of the sensitivity analyses assuming correlated baseline covariates. All considered methods were derived using simulated samples of size 17,000 and true prediction c-statistic of 0.75.",fig.align='center'}
knitr::include_graphics(here::here("figures/ch4-rmse_moderate_sample_size_sensitivity.pdf"))
```

```{r fig-ch4-supp13, cache=FALSE, echo=FALSE, fig.cap="RMSE of the sensitivity analyses assuming correlated baseline covariates. All considered methods were derived using simulated samples of size 4,250 and true prediction c-statistic of 0.85",fig.align='center'}
knitr::include_graphics(here::here("figures/ch4-rmse_moderate_auc_sensitivity.pdf"))
```

## Empirical illustration {.unnumbered}

For predicting baseline risk of 30-day mortality we fitted a logistic regression
model with age, Killip class (*Killip*), systolic blood pressure (*sysbp*),
pulse rate (*pulse*), prior myocardial infarction (*pmi*), location of
myocardial infarction (*miloc*) and treatment as the covariates. Baseline
predictions were made setting treatment to 0.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
load(here::here("data/introduction/gusto.rda"))
gusto <- gusto %>%
  tibble() %>%
  filter(!is.na(tpa))

gusto <- gusto %>%
  tibble() %>%
  filter(tx != "SK+tPA") %>%
  rename(
    "outcome" = "day30",
    "treatment" = "tpa"
  )

treatmentArms <- gusto %>%
  group_by(treatment) %>%
  summarise(n = n())

prediction <- glm(
   outcome ~ treatment + age + Killip + pmin(sysbp, 120) + lsp(pulse, 50) + pmi + miloc,
   data = gusto,
   family = "binomial",
   maxit = 99
)

predictionCoefficients <- coef(prediction)
predictionCoefficients <- predictionCoefficients[c(1, 3:12, 2)]
```


\begin{equation*}
P(outcome=1|X=x) = \text{expit}(lp(x)),
(\#eq:gusto1)
\end{equation*}
where 
\begin{equation*}
\begin{aligned}
lp(x)=& \beta_0 + \beta_1 \text{age} + \beta_2 I(\text{Killip}=II) + \beta_3I(\text{Killip}=III) +\\
&\beta_4 I(\text{Killip}=IV) + \beta_5min(\text{sysbp}, 120) + \beta_6 \text{pulse}+\\
&\beta_7 max(\text{pulse - 50, 0}) + \beta_8 I(\text{pmi}=yes)+\\
&\beta_9 I(\text{miloc}=Anterior) + \beta_9 I(\text{miloc}=Other) +\\
&\gamma\times\text{treatment}
\end{aligned}
(\#eq:gusto2)
\end{equation*}

and $expit(x) = \frac{e^x}{1+e^x}$

```{r, echo=FALSE}
predictionSummary <- summary(prediction)
# predictionSummaryCoef <- tibble(predictionSummary$coefficients) %>%
#   rownames_to_column("Variable")

predictionCoefficientsTable <- predictionSummary$coefficients %>%
  as.data.frame() %>%
  mutate(
    rownames = c(
      "Intercept",
      "Age",
      "Killip class = II",
      "Killip class = III",
      "Killip class = IV",
      "Systolic blood pressure",
      "Pulse rate (1)",
      "Pulse rate (2)",
      "Previous MI (yes)",
      "MI location (Other)",
      "MI location (Anterior)",
      "Treatment"
    )
  ) %>%
  rownames_to_column("Variable") %>%
  select(-Variable) %>%
  select(rownames, everything())
  
colnames(predictionCoefficientsTable) <- c(
  "Variable",
  "Estimate",
  "stderror",
  "zvalue",
  "pvalue"
)
  
kableExtra::kbl(
  predictionCoefficientsTable,
  format = "latex",
  escape = FALSE,
  longtable = TRUE,
  align = c("l", rep("r", 4)),
  booktabs = TRUE,
  caption = "Coefficients of the prediction model for 30-day mortality, based on the data from GUSTO-I trial.",
  digits = 3,
  linesep = "",
  format.args = list(
    big.mar      = ",",
    decimal.mark = "."
  )
) %>%
  kableExtra::kable_styling(font_size = 7)
```

## Bootstrap confidence intervals {.unnumbered}

Bootstrap confidence intervals in Figure 6 of the main manuscript were derived
using the following approach:

1. Draw with replacement a sample $D^*$ from the original dataset $D$ of the
same size as $D$.

2. Fit a logistic regression model $m^*$ in $D^*$ to predict 30-day mortality
using the same covariates as the initial model $m$ estimated in $D$.

3. Using the linear predictor $\hat{lp}^*$ of model $m^*$, fit models for
constant relative treatment effect, linear interaction of the linear predictor
with treatment, and interaction of treatment with a restricted cubic splines
transformation of the linear predictor in $D^*$, as described in the *Methods*
section.

4. Based on $m^*$, use predicted risks to stratify $D^*$ into risk quarters and
estimate absolute treatment effects within risk strata.

5. Repeat steps 1 through 4 for a total of $b=10000$ times.

6. Derive the confidence band for each continuous method (not risk
stratification) as follows:
    a. Split the range $(0, 0.25]$ of baseline risk values into 499 equal-length
    intervals of the form $(p_0,p_1],\dots,(p_{498}, p_{499}]$.
    b. For a specific point $p_k,k=1\dots,499$ and each method $i$, use the 2.5
    and 97.5 percentiles of the $b$ absolute benefit estimates to define the
    confidence interval $(q_{0.025}^{i,p_k},q_{0.975}^{i,p_k})$.
7. Derive two sets of confidence intervals for the risk stratification approach
as follows:
    a. *Treatment effect:* For each risk quarter identified by the original
    model $m$ developed on $D$, the confidence interval for the mean absolute
    treatment effect is derived from the 2.5 and 97.5 percentiles of the mean
    absolute treatment effects estimated within each risk quarter across the $b$
    bootstrap samples.
    b. *Mean predicted risk:* For each risk quarter identified by the original
    model $m$, the confidence interval for the quarter-specific mean predicted
    risk is derived from the 2.5 and 97.5 percentiles of the mean predicted
    risks estimated within each risk quarter across the $b$ bootstrap samples.

