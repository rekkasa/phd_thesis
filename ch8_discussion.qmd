# General discussion

\vspace*{\fill}\par
\pagebreak

## Main findings 

This thesis had three main research aims (Box \ref{resultsBox}). In chapter
@sec-review we reviewed the available literature on predictive approaches to
treatment effect heterogeneity. In chapter @sec-framework we presented a
standardized framework for the assessment of treatment effect heterogeneity
using a risk-based approach in observational data. We applied this framework in
two different clinical settings. First, we evaluated effect heterogeneity of
thiazides or thiazide-like diuretics compared to angiotensin-converting enzyme
inhibitors for the treatment of hypertension (chapter @sec-framework). Second,
we evaluated treatment effect heterogeneity of teriparatide compared to oral
bisphosphonates for patients with osteoporosis (chapter @sec-osteoporosis). In
chapter @sec-simulation we presented risk-based approaches for predicting
individualized treatment effect. Finally, in chapters @sec-melanoma and
@sec-covid we presented the development and validation of models for
prediction of baseline risk in melanoma and COVID-19 patients.

\begin{blackbox}[label={resultsBox}]{Results regarding the aims of this thesis}
\textbf{Aim 1}: \textit{Systematically review the current literature on predictive
approaches to treatment effect heterogeneity}.
\begin{itemize}
\item We found 36 papers on regression-based methods. Based on the reference class for patient similarity regarding treatment effect heterogeneity, we categorized existing methods to risk modeling (similarity based on risk factors), treatment effect modeling (similarity based on risk factors and effect modifiers), and optimal treatment regime methods (similarity based solely on effect modifiers).\newline
\end{itemize}
\textbf{Aim 2}: \textit{Develop scalable and reproducible risk-based predictive approaches to the assessment of treatment effect heterogeneity}.
\begin{itemize} 
\item We developed a standardized five-step framework for evaluating treatment
effect heterogeneity within the observational setting using
a risk-based approach.
\item We found in simulations that a simple linear interaction of baseline risk 
with treatment adequately predicted absolute treatment effects for individual
patients in many common scenarios.\newline
\end{itemize}
\textbf{Aim 3}: \textit{Apply risk-based methods to better guide medical decisions}
\begin{itemize}
\item We developed and validated a prediction model for sentinel node positive
melanoma patients.
\item We developed and validated a prediction model for predicting mortality
and need for intensive care unit admission in patients who present to the emergency
department with suspected COVID-19. We implemented the model in publicly available
online applications.
\item We evaluated effect heterogeneity of teriparatide treatment compared to
treatment with oral bisphosphonates in osteoporosis patients using our five-step
framework.
\end{itemize}
\end{blackbox}

## Review of the literature

In our scoping literature review we categorized the 36 extracted papers with
regression-based methods using their definition of the reference class, i.e.,
the subset of observed patient characteristics used to describe patient
similarity in terms of expected treatment effects. We identified three different
approaches to regression-based evaluation of treatment effect heterogeneity:
risk-based methods, treatment effect modeling methods, and optimal treatment
regime methods (Box \ref{literatureBox}).

Risk-based approaches define patient similarity based solely on risk factors.
They can be further divided into risk stratification approaches that rely on the
definition of risk-based subgroups of patients and risk magnification approaches
that assume a constant relative treatment effect. The latter can also be used to
make personalized benefit predictions. In chapter \@ref(simulation), the strong
assumption of constant relative treatment effects was relaxed, allowing for
increasingly linear and non-linear interactions of baseline risk with treatment.

Treatment effect modeling methods focus both on risk factors and treatment
effect modifiers to predict personalized treatment effects. They are more
intuitive, in the sense that they attempt to account for all dimensions of
treatment effect heterogeneity. However, statistical power is an important
constraint, as multiple treatment-covariate interaction effects need to be
estimated. In the presence of well-documented and clinically supported effect
modifiers statistical power may suffice, as only a small pre-defined set of
interaction effects will be evaluated (**REFS: bmj/path**). Penalization
methods, shrinking treatment-covariate interactions towards 0, have been shown
to improve performance of treatment effect modeling methods. For example,
[Basu etal](https://journals.plos.org/plosmedicine/article/file?id=10.1371/journal.pmed.1002410&type=printable)
developed models for predicting individualized benefits and harms from intensive
blood pressure treatment. They found that in the case of predicting adverse
events---a setting with limited prior knowledge on effect modification---using
elastic net penalization improved performance compared to a backward elimination
approach. Similar conclusions were drawn in the simulation study of
[van Klaveren et al](https://www.sciencedirect.com/science/article/pii/S0895435618310072?via%3Dihub),
where LASSO penalization resulted in smaller errors compared to an unpenalized
approach, in the presence of true effect modification.

Staging approaches relying on the calibration of first-stage "working" models
with a large set of treatment-covariate interactions have also been suggested
for estimating personalized treatment effects (**REFS**). 
[Kunzel et al](https://www.pnas.org/doi/epdf/10.1073/pnas.1804597116),
focusing on machine learning approaches, proposed an organization of staging
methods, categorizing them into A-learners and S-learners. Assuming binary
treatment assignment, A-learners fit treatment-arm specific models before
estimating individualized treatment effects as their difference. S-learners
include treatment assignment in the development of the tree-based model.
Conditional average treatment effect is then estimated as the difference between
setting the treatment indicator to control and active treatment. Finally, they
introduced the class of X-learners. First-stage outcome models are fitted
separately in each treatment arm to impute coutnerfactual outcomes, thus
generating an “observed” treatment effect. Any regular modeling approach can
then be used to estimate treatment effects (**Needs larger data??**)

Finally, optimal treatment regime methods focus on modeling treatment effect
modifiers for the evaluation of treatment effect heterogeneity. Their aim is not
to provide personalized treatment effect estimates or to separate patients into
subgroups of similar expected treatment effect, but rather to classify them into
two categories: patients who benefit from treatment and patients who do not. If
there are no major treatment-related harms or costs, they can be used out of the
box to guide medical decisions. However, in the presence of serious treatment
adverse events, these methods may be more challenging to implement, as the
effect of baseline risk factors is not taken into account. This means that the
baseline risk of the main outcome of interest is not evaluated and, therefore,
the absolute risk reduction achieved with treatment cannot be compared to the
risk increase for the adverse event in question.

In a similar literature review focusing on subgroup idenetification, 
[Lipkovich et al](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.7064)
divided existing methods into three main categories. The more general approach,
global outcome modeling, builds a global model for the outcome of interest often
including a large number of covariates and interactions of many of these
covariates with treatment. As this approach is quite challenging in its
implementation due to low power and limited knowledge on treatment effect
modification, Lipkovich et al identified two main simplification approaches.
First, global treatment effect modeling approaches focus only on the estimation
of treatment-covariate interactions foregoing the estimation of purely
prognostic covariate effects. The definition of this set of methods is very
similar to the optimal treatment regime category of chapter \@ref(review).
Second, local modeling methods focus on the identification of regions of the
covariate space with desirable treatment effects. In this way, an outcome model
is only required to adequately perform locally, avoiding the need to extend the
derived models to covariate regions with limited information. Risk modeling
methods presented in chapter \@ref(review) can also be considered as an
additional simplification approach, since they assume that treatment effect only
interacts with baseline risk.

Our study had several limitations. We focused our review on the clinical trial
setting and only regression modeling methods were considered. The analyzed
literature was identified through a mix of systematic literature search and
suggested literature identified by an expert panel. Though this may have
resulted in a more targeted initial selection of reviewed publications, it is
possible that not all of the relevant literature was captured. However, the main
finding of the review, i.e., a systematic categorization of the predictive
methods for the evaluation of treatment effect heterogeneity, is probably robust
against missing citations. Furthermore, literature  on treatment effect
heterogeneity has been growing rapidly since our literature review in 2020
(**need citations??**).

Evaluation of treatment effect heterogeneity is not a problem specific to
healthcare research with important advances being made in economics, social
sciences, and other fields (**REFS**). In addition, the increasing availability
of observational data from extensive databases capturing a large proportion of
patients' interaction with the healthcare system has provided additional
challenges, with confounding, suboptimal data capture, local or temporal
inconsistencies only being a few of them. These challenges have resulted in the
introduction of novel methods for the evaluation of treatment effect
heterogeneity. 

\begin{blackbox}[label={literatureBox}]{Organization of existing literature}
\textbf{Risk-based methods:} \textit{Patient similarity is defined solely based
on risk factors}.
  \begin{itemize}
    \item Interactions of baseline risk with treatment are modeled.
    \item Risk stratification approaches identify risk of homogeneous treatment
    effect.
    \item Risk magnification approaches assume a constant relative treatment
    effect\\
  \end{itemize}
  
\textbf{Treatment effect modeling methods:} \textit{Patient similarity is
defined based on both risk factors and treatment effect modifiers}.
  \begin{itemize}
    \item The main effects of risk factors are modeled along with interactions
    of effect modifiers with treatment.
    \item Statistical power is an important constraint\\
  \end{itemize}
  
\textbf{Optimal treatment regime methods:} \textit{Patient similarity is
primarily defined based on treatment effect modifiers}.
  \begin{itemize}
    \item Rely on accurately estimating interactions of effect modifiers with
    treatment.
    \item Aim to separate patients into two categories: those who benefit from
    the treatment under study and those who do not.
    \item In the presence of serious treatment-related harms may be challenging
    to implement.
  \end{itemize}
\end{blackbox}


## Risk-based predictive approaches to treatment effect heterogeneity

In this thesis, we separate predictive approaches (predict which treatment will
result in better outcomes for an individual) from causal
approaches (exploratory or confirmatory subgroup analyses) for the evaluation
of treatment effect heterogeneity, focusing on the former. The Predictive
Approaches to Treatment effect Heterogeneity (PATH) statement aimed to provide
guidance on the conduct of predictive analyses of treatment effect heterogeneity
(**REF: PATH**). Using variation in risk difference across patient subgroups as
the point of clinical relevance, the PATH statement presented comprehensive
guidance on performing risk-based evaluation of treatment effect heterogeneity.
It explored the settings within which a risk-based approach would be most
appropriate. It provided guidance on best practices when undertaking a
risk-based approach for the evaluation of treatment effect heterogeneity and
presented its limitations. Finally, it identified several knowledge gaps that
need to be addressed in future research. Among many others, the need for further
research in the evaluation of treatment effect heterogeneity in observational
data and methods for individualization of predicted treatment effect were
highlighted. Research on both these knowledge gaps was presented in this thesis
(chapters \@ref(framework) and \@ref(simulation)).

In chapter \@ref(framework), we proposed a five-step standardized framework for
evaluating treatment effect heterogeneity within the observational setting using
a risk-based approach (box \ref{frameworkBox}). We alse developed a software
package for performing such analyses. We made our software compatible with
databases mapped to OMOP-CDM to allow for scalability and reproducibility of the
analyses. The potential of this approach was demonstrated in a small-scale
analysis of effect heterogeneity in the treatment of hypertension, while a more
thorough application in the treatment of osteoporosis was presented in chapter
\@ref(osteoporosis).

For the definition of the research aim we need to clearly define the set of
characteristics required to qualify patients for any of the following sets: the
treatment set (i.e. the patients within a database receiving the treatment under
study); the comparator set (i.e., the set of patients within a database receiving
the control treatment); one or more outcome sets (i.e., the sets of patients
within a database that experience the outcomes of interest). Once the relevant
databases to be included in the study have been identified, we can proceed with
patient extraction in order to generate the study population for each database.

Consecutively, for each database, we develop prediction models for the outcomes
of interest. We develop the prediction models on the propensity score matched
subsets of the study populations, in order to avoid overfitting to one of the
treatment arms. We then use the predictions of these models to stratify the
study population of each database into a predefined number of risk groups.

Within risk strata we develop separate propensity score models. We then estimate
relative and absolute treatment effects within strata, adjusting for the
observed confounding using the derived risk-stratum specific propensity scores.
At this point it is important to analyze diagnostics for the validity of the
derived estimates. Adjustment for observed confounding can be evaluated both at
database level and within risk strata by plotting the standardized mean
differences of the study covariates before and after propensity score
adjustment. The presence of unobserved confounding can be evaluated using
negative control analyses (**REF**). These use treatment effect estimates on a
large number of causally unrelated outcomes to any of the treatments under study
to approximate the observed null distribution and contrast it to the theoretical
one. Once all the results have been generated and evaluated for their validity,
risk stratified forest plots of treatment effects on both the relative and the
absolute scale can be generated in all available databases.

The proposed framework provides an extension of the PATH statement (**REFS**) to
the observational setting using a standardized approach. The open-source
software we developed for implementing our framework enables highly complex
analyses allowing for multiple stratification schemes and analysis approaches.
It is also highly scalable as any set of analyses could be implemented across a
global network of observational databases mapped to OMOP-CDM.

\begin{blackbox}[label={frameworkBox}]{Standardized framework}
Our standardized framework for risk-based assessment of treatment effect
heterogeneity consists of five steps:
\begin{enumerate}
\item \textit{Definition of the research aim}
\item\textit{Identification of the relevant databases}
\item\textit{Development of prediction model(s) for the outcome(s) of interest}
\item\textit{Estimation of relative and absolute treatment effects within strata of predicted outcome risk}
\item\textit{Presentation of the results}
\end{enumerate}
\end{blackbox}

Risk stratified approaches to treatment effect heterogeneity estimate treatment
effects for groups of patients with more similar, but not necessarily equal,
baseline risk. Consequently, with larger variability in predicted risk and
strong treatment effects, strata-specific estimates of treatment effect may not
apply to individuals.

In chapter \@ref(simulation), we compared regression-based methods for
personalizing predictions of treatment effect using baseline risk in a
simulation study. Focusing on the RCT setting, methods assuming a constant
relative treatment effect, or a linear interaction of the linear predictor for
risk with treatment, or finally non-linear interactions in the form of
restricted cubic splines were compared. Additionally, an adaptive approach using
Akaike's Information Criterion was also evaluated.

No single method outperformed the other methods across all scenarios. However, a
linear interaction model performed adequately in most scenarios, while the more
flexible restricted cubic splines methods and the adaptive methods required
larger sample sizes. The findings of our simulations express the trade-off
between the advantages of flexibly modeling the relationship between baseline
risk and treatment effect and the disadvantages of overfitting this relationship
to the sample at hand.

Although risk is a mathematical determinant of treatment effect, an important
limitation of risk-based methods for the evaluation of treatment effect
heterogeneity is the imposition of strong assumptions on the relationship
between treatment effect and risk factors. Since treatment benefit is modeled as
a function of predicted baseline risk, all risk factors are assumed be similarly
associated with treatment effect. More specifically, the effects of risk factors
on treatment effect are assumed to be proportional to their effect on baseline
risk (**REF: Hoogland et al**). Even though models allowing for individual
treatment-covariate interactions may be considered more realistic, estimation of
these interaction effects can be very challenging. (**REFS!!**). Randomized
controlled trials are often adequately powered for the detection of a main
treatment effect and not for the estimation of interaction effects.
Consequently, interaction effects are often overestimated, leading to major
overestimation of treatment effect heterogeneity ("overfitting").

Therefore, in settings with smaller sample sizes, absence of information on
treatment effect modification, or a large number of candidate effect modifiers,
the adoption of a risk-based approach for the evaluation of treatment effect
heterogeneity is appropriate. In these settings, the bias introduced
by---potentially falsely---assuming that treatment effect is a function of
baseline risk may still result in more accurate representation of treatment
effect heterogeneity, compared to a highly variable treatment effect modeling
approach. With larger sample sizes or well-studied treatment effect
modification, treatment effect modeling may be the optimal approach. Again,
special care, such as penalization of interaction effects may still be required
as a measure against overfitting (**REFS!!**). In general, there is no single
approach that can universally outperform all others, but it grossly depends on
the setting at hand.

In our simulation study we only considered risk modeling approaches and did not
compare them with treatment effect modeling methods. As already explained,
depending on the setting, one approach may outperform the other when
individualizing treatment benefits. The considered simulation scenarios always
assumed the presence of true interactions of treatment with baseline risk,
without allowing for interactions of treatment with individual predictors. In a
small set of additional simulation scenarios, the performance of the considered
risk-based methods was evaluated in the presence of true treatment-covariate
interactions. Despite the main conclusions remaining unchanged, the errors for
all approaches increased considerably. In these scenarios, using a treatment
effect modeling approach with appropriate penalization on the interaction
effects may have performed better with larger sample size and/or strong
treatment-covariate interactions (**REF van Klaveren, Simulations**).

With the development of the framework presented in chapter \@ref(framework) our
aim was to enable the evaluation of treatment effect heterogeneity using readily
available observational patient data, while avoiding much of the cost for
setting up a clinical trial. Despite its great promise, however, observational
data suffers from major imbalances in treatment assignment, great disparities in
the level clinical information is captured between different vendors, and
high-dimensionality (**REFS!!**). Consequently, traditional statistical
inference methods often fail to produce unbiased treatment effect estimates.
Despite great advances in methods research with observational data, strong
assumptions---often unverifiable---are required to overcome very fundamental
design limitations (**Varadhan et al, 2013**).

In the development of the framework in chapter \@ref(framework), considerable
attention is given to the evaluation of diagnostics at every step of the
process. More specifically, the overlap of the propensity score distributions
between treatment arms along with the balance in standardized covariate means
after propensity score adjustment are evaluated. However, these approaches only
focus on adjustment for observed confounding, i.e. confounding that can be
eliminated by conditioning on observed covariates. Consequently, both the
overall and the risk-stratified treatment effect estimates, can still be biased
due to unobserved confounding. Using negative control analyses we can evaluate
the presence of unobserved confounding and---to some extent---calibrate the
derived estimates.

## Applications

\begin{blackbox}[label={applications}]{Summary of applications}
We carried out the following applications of risk-based methods to better guide
medical decisions:
\begin{itemize} 
\item Prediction of 5-year risk of recurrence, distant metastasis, and overall
mortality in patients with sentinel node postitive melanoma
\item Prediction of 28-day risk of ICU admission and death in patients
presenting at the emergency department with suspected COVID-19
\item Risk-based evaluation of teriparatide treatment effect heterogeneity
compared to treatment with oral bisphosphonates in patients with osteoporosis
\end{itemize}
\end{blackbox}

We developed and externally validated a nomogram for the prediction of
recurrence, distant metastasis, and overall mortality 5-year risk positive
sentinel node (SN) melanoma patients. We initially fitted a Cox regression model
for recurrence using four baseline covariates. Models for distant metastasis and
overall mortality were derived by recalibrating the baseline hazard and the
slope of the recurrence prediction model. As the MSLT-II trial (**REF**) found
no survival benefit for completion lymph node dissection the number of involved
non-SNs will often not be available when risk stratifying positive SN melanoma
patients. In our prediction model we found minor performance drop when using SN
tumor burden as a surrogate. In addition, the developed prediction models were
better able to discriminate high from low risk patients compared to the American
Joint Committee on Cancer staging system, thus identifying a more robust
low-risk group in whom it may be justified to forego adjuvant therapy.

We developed models for the prediction of 28-day mortality and admission to the
intensive care unit (ICU) in patients presenting at the emergency department
with suspected COVID-19. The prediction models were developed in patients from
four hospitals in the Netherlands during the first COVID-19 wave (March through
August 2020) and temporally validated on patients of the second wave (September
through December 2020). The proposed models were based on quickly and
objectively obtainable predictors (**REFS**). Prediction of ICU admission risk
is challenging as it depends on national, regional or hospital practices, as
well ICU bed availability. In addition, as was already pointed out in chapter
\@ref(covid), patients admitted to the ICU tended to be younger than the
patients being discharged due to decisions not to admit frail patients. For the
development of our prediction model for ICU admission, the strong correlation
between death and need for intensive care was exploited, by recalibrating the
mortality prediction model for the outcome of ICU admission. The prediction
models displayed good performance (discrimination and calibration) in the
validation set, were easy to use, and were freely available online and with
mobile applications.

The prediction models of chapters \@ref(melanoma) and \@ref(covid) are
applicable to the populations from which the model development samples were
drawn. The general problem of transportability of prediction models in space and
time is an important issue, that needs to be considered when evaluating
prediction models 
(**REFS:** [van Calster et al, 2023](https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-023-02779-w) and [Luijken et al, 2019](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.8183)).
Patient populations can vary substantially over time as they become older,
lifestyle habits evolve, and new treatments become available. Same with
measurements of predictors, they can be different depending on the time they
were made. In addition, the characteristics of populations located in different
places may be be significantly different compared to the model development
population and disparities in data capture may also be present. To that end, we
externally validated the EORTC-DeCOG nomgram of chapter \@ref(melanoma) in data
from Germany and adopted a leave-one-center-out validation approach for the COPE
prediction model of chapter \@ref(covid).

Prediction models for COVID-19 are not easily transportable to settings outside
the ones they were actually developed
(**REFS:** [van Klaveren et al, 2022](https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-022-02651-3)).
Response to COVID-19 has been characterized with large geographical and temporal
disparities (**REF**), as have the severity and progression of disease.
Therefore, our developed prediction model of chapter \@ref(covid) could be
safely applied to aid medical decision making in the Netherlands during the
earlier stages of the pandemic. However, its generalizability to other
healthcare systems needs to be explored. In addition, evaluation of its temporal
validity in subsequent periods is required and, if found necessary, the model
should be updated. Recent work has shown promising results with the application
of a model updating framework
(**REFS:** [Levy et al, 2022](https://www.nature.com/articles/s41467-022-34646-2)).

## Future research

A review of the fast-growing literature in the observational setting using the
suggested categorization approach needs to be carried out. Due to the added
complexity (large patient numbers, large number of captured covariates, data
quality issues, and many more) focus has shifted from regression modeling
methods to more automated machine-learning approaches. Consequently, treatment
effect modeling and optimal treatment regime methods have become more prevalent
(**REFS**). The categorization approach suggested can be used to guide this
endeavor, while also it can be further generalized to account for the
fundamental differences between settings.

A large-scale application of the framework for risk-based assessment of
treatment effect heterogeneity in the observational setting should be carried
out to better demonstrate its potential for providing better insight to the
derived overall treatment effect estimates. The comparison of thiazides or
thiazide-like diuretics to ACE inhibitors presented as a demonstration in the
presentation of the framework was based on a limited set of treatments and
outcomes used in a very large observational study (**REF Legend**). That study
compared first-line treatments for hypertension across an extensive network of
observational databases from around the world. Extension of the small-scale
application to the entire set of comparisons considered in that study is a
realistic aim.

For example, the PATH statement suggested developing the internal prediction
model on the pooled study population to avoid biases in the risk stratified
treatment effect estimates, both on the relative and the absolute scale (**REF:
van Klaveren, Simulation; Burke, 2014; Abadie**). Despite this being
straightforward to implement within the RCT setting, the systematic differences
of patient characteristics between treatment arms in the observational setting
complicate risk stratification for the evaluation of treatment effect
heterogeneity. In our framework we developed the internal prediction model on
the propensity score matched subset of the study population. Even though this
approach achieves balance between treatment arms, it effectively modifies the
target population of the prediction model. Consequently, further research on the
modeling approaches of the framework are required.

The proposed approaches to modeling interactions of baseline risk with treatment
compared in the simulation study of chapter \@ref(simulation) need to be
extended to the observational setting and evaluated in an extensive simulation
study. Extensive literature on machine learning algorithms for estimating
conditional average treatment effects and for correcting overfitted
regression-based treatment effect modeling approaches provides a broad set of
candidate methods for the evaluation of treatment effect heterogeneity on the
observational setting. A head-to-head comparison of these methods and the
proposed risk-based approaches can provide further insights into their relative
performance and help guide model selection and implementation in different
settings.
